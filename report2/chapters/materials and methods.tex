\section{Materials and Methods}

In medical image analysis, a typical workflow involves executing several sequential algorithmic steps, a process collectively referred to as a pipeline \cite{b8}. The pipeline in this study consists of six steps, namely pre-processing, registration, feature extraction, classification, post-processing and evaluation.

\subsection{Pre-processing}
The pipeline begins with data crawling and preprocessing. A FileSystemDataCrawler organizes image directories, and \texttt{pre\_process\_batch} performs operations such as skull stripping, intensity normalization, and for the atlas affine registration is performed  \cite{b9}. Preprocessing parameters can be adjusted to include gradient intensity and coordinate-based feature extraction.
% Ex: For the machine-learning approach, we proceeded with a skull stripping. 
% Ex: As an additional experimental feature, we implemented a sort of reverse pre-processing and added salt & peppper noise to our images to evaluate our models on noisy data.

\subsection{Registration}

Registration is used to align multiple images to a common reference frame. When only rotations and translations are involved, it is referred to as a rigid transformation while, when scale and skew factors are also included, it is referred to as an affine transformation. Nonlinear, deformable transformations also exist \cite{b10}.

\# TODO: describe what registration we used, for atlas-related I suggest we speak about it in other section
% Ex: In this study, we aligned the T1- and T2-weighted images. 
% Ex: Registration was also used while constructing the atlas but this is discussed in an ensuing section.

\subsection{Feature Extraction}

Any extractable characteristic or property that describes the underlying medical image and is used in the analysis is coined as a feature. Some examples of image features are intensity, shape and texture information \cite{b8}.

\# TODO: describe what features we used and how it was extracted

\subsection{Classification}

Classification is the core of the automated segmentation process. It is during this step that the chosen machine learning algorithm decides which label to assign to a given voxel \cite{b8}. All previous steps of the pipeline are tuned such that the best label assignment result is obtained. In this study, a random forest machine learning algorithm was used.

\# TODO: describe the parameters used in our implementation of the RF

\subsection{Post-processing}

With the predicted labels obtained, post-processing ensures that these segmentation results are cleaned, polished and improved. Some common examples are smoothing operations and morphological filters to remove noise, refine contours and fill in holes \cite{b11}.

\# TODO: What did we do to ML results? What did we do to the atlas?

\subsection{Evaluation}

The final step of the pipeline is to quantitatively assess its performance. Such a numeric score is a quick and easy way to compare and contrast different pipelines. Note that qualitative assessment of the resulting segmentation results is also very important to consider when deciding the clinically "better" result.

Dice scores quantify the segmentation quality for each tissue type (e.g., gray matter, white matter) \cite{b12}. Evaluator tools calculate subject-wise and aggregated statistics, including mean and standard deviation, across test samples. Results are logged and saved in timestamped directories for analysis.

\subsection{Construction of Atlas Labels}
A reference atlas serves as a common space for alignment. Training images are divided into subsets (e.g., 10 per atlas), which are registered to the reference atlas using affine transformations. Within each subset, atlases are constructed by assigning each voxel the label that occurs most frequently across all images in the subset. This majority-vote strategy ensures consistent labeling across atlases. Additionally, morphological operations, including median filtering and opening/closing, refine segmentation quality and eliminate small artifacts.

To account for variability across atlases, Dice scores calculated during validation are used to weight atlas contributions. A weighted atlas is then constructed by aggregating label-specific contributions of individual atlases based on their performance.




