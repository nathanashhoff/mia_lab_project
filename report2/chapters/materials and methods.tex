\section{Materials and Methods}

In medical image analysis, a typical workflow involves executing several sequential algorithmic steps, a process collectively referred to as a pipeline \cite{b8}. The pipeline in this study consists of pre-processing, registration, feature extraction, classification, post-processing and evaluation. 

Regarding the experimental data, we utilized 20 training sets and 10 test sets of T1-weighted (T1w) and T2-weighted (T2w) MRI sequences, each accompanied by ground truth segmentation labels, brain masks and an affine transformation matrix to a provided reference atlas.

\subsection{Pre-processing}

As an initial step, pre-processing functions to refine and standardize all images in a dataset. Some common actions include background removal, noise reduction, intensity normalization and resampling \cite{b9}.

In our implementation, the pipeline began with intensity normalization, executed via Z-score normalization. This method computed the mean and standard deviation of pixel intensities, standardizing them to a zero-mean, unit-variance distribution. This step mitigated inconsistencies across the dataset. Next, skull stripping was performed, which applied binary masks to remove non-brain regions. This ensured only relevant anatomical structures were retained.

Additionally, we introduced artificial salt-and-pepper noise. This step was not part of standard pre-processing but was incorporated to test model robustness under lower image quality conditions.

% Ex: For the machine-learning approach, we proceeded with a skull stripping. 
% Ex: As an additional experimental feature, we implemented a sort of reverse pre-processing and added salt & peppper noise to our images to evaluate our models on noisy data.

\subsection{Registration}

Registration is used to align multiple images to a common reference frame. When only rotations and translations are involved, it is referred to as a rigid transformation while, when scale and skew factors are also included, it is referred to as an affine transformation. Nonlinear, deformable transformations also exist \cite{b10}. Since the corresponding affine transformations were provided in the dataset, the registration step was skipped during the Random Forest training.
% Ex: In this study, we aligned the T1- and T2-weighted images. 
% Ex: Registration was also used while constructing the atlas but this is discussed in an ensuing section.

\subsection{Feature Extraction}

Any extractable characteristic or property that describes the underlying medical image and is used in the analysis is coined as a feature. Some examples of image features are intensity, shape, and texture information \cite{b8}. In this study, we focused on extracting features that encapsulate spatial, textural, and statistical properties from the T1w and T2w MRI sequences.

Textural features, derived from local intensity distributions, were used to capture patterns and variations within tissue regions. These included metrics such as mean intensity, variance, skewness, and entropy, which are particularly valuable for distinguishing between homogeneous and heterogeneous structures. These features enable the identification of subtle differences in tissue composition. Statistical sampling of voxel intensities provided additional insights by focusing on representative subsets of the data. By generating masks to ensure balanced sampling across different labels, we accounted for variations in tissue representation and minimized the impact of class imbalance. This approach not only improved the quality of the feature set but also enhanced the training process for the Random Forest model.

%The combination of these features ensured a robust and multidimensional characterization of the images, facilitating effective downstream processing and analysis.

\subsection{Classification}

Classification is the core of the automated segmentation process, where the chosen machine learning algorithm determines the label for each voxel in the image \cite{b8}. In this study, a Random Forest classifier was utilized due to its robustness in handling high-dimensional data and its resistance to overfitting.

To optimize the classifier’s performance, a grid search was conducted to determine the best hyperparameters for both the original and the simulated noisy datasets. Interestingly, the same optimal hyperparameters were identified for both conditions, indicating the classifier’s adaptability to different data qualities. The model achieved the best results with 700 decision trees, a maximum tree depth of 45, and a square root selection of features at each split.

The Random Forest was trained on features extracted from the pre-processed images, and its predictions on test data provided voxel-level probabilities for each label. These outputs formed the basis for the subsequent evaluation step.


\subsection{Post-processing}

In this study, post-processing was not applied as it was not necessary to evaluate our hypothesis. The results were directly assessed to determine the segmentation performance, ensuring that the findings reflected the core methodologies without additional modifications.

% \# TODO: What did we do to ML results? What did we do to the atlas?
%Should we maybe just remove this subsection because we dont use any postprocessing?

\subsection{Evaluation}

The final step of the pipeline is to quantitatively assess its performance. Such a numeric score is a quick and easy way to compare and contrast different pipelines. Note that qualitative assessment of the resulting segmentation results is also very important to consider when deciding the clinically "better" result.

Dice similarity coefficients quantify the segmentation quality for each tissue type (e.g., gray matter, white matter) \cite{b12}. Evaluator tools calculate subject-wise and aggregated statistics, including mean and standard deviation, across test samples. Results are logged and saved in timestamped directories for analysis.

\subsection{Construction of Atlas Labels}
A reference atlas serves as a common space for alignment. All training images were used for generating the atlas labels by registering the segmentation labels of each patient to the provided reference atlas using the given affine transformations. The atlas labels are constructed by averaging all the individual patient labels from the training set and then assigning each voxel the label that occurs most frequently. Additionally, morphological operations, such as median filtering and Opening and Closing, were applied to refine segmentation quality and eliminate small artifacts.




